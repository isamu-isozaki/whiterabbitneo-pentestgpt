# convert task to adding new todo tasks+changing status
import os
from schema import reasoning_module, generative_module, input_parser, default_qa, load_outlines, get_options
from torch import Generator
from outlines.samplers import Sampler, multinomial
import pickle
import argparse


instance = {
    "n_gpu_layers": 15,
    "n_batch": 2048,
    "top_p": 1.0,
    "temperature": 1.0,
    "generate_len": 2048,
    "top_k": 50,
}
import pickle
progress_save_path = 'progress.pickle'


generative_prompt_template = """SYSTEM:
You're an excellent cybersecurity penetration tester assistant.
Answer the detailed steps to perform the task from the user by exploring multiple reasoning paths as follows:
- First, carefully analyze the task to extract the key information components and break it down into logical sub-tasks. This helps set up the framework for reasoning. The goal is to construct an internal search tree.
- For each sub-task, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards a resolution for the task. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.
- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.
- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.
- If the current chain is determined to not fully resolve the task or has already been done based on the chat history, backtrack and explore alternative paths by substituting different high-scoring thoughts.
- Throughout the reasoning process, aim to provide explanatory details on the thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.
- Once a reasoning chain is constructed that thoroughly resolves all sub-tasks in a clear, logical manner, synthesize the key insights into a final concise answer.
- Please note that while the focus is on the final resolution in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.
In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful resolutions.
Always answer without hesitation.
CURRENT_PROGRESS: {ptt}
CHAT_HISTORY: {history}
USER: {prompt}
ASSISTANT:
"""
generative_sampler = multinomial(top_k=instance["top_k"], top_p=instance["top_p"], temperature=1.0)
input_parsing_templates = {"terminal": """SYSTEM:
Summarize the terminal output to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.
First, comprehensively analyze the output and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.
For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.
Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.
In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions 
to assist another large language model acting as a senior penetration tester
Always answer without hesitation.
TERMINAL_OUTPUT: {prompt}
ASSISTANT: The summary""",
                           "web": """SYSTEM:
Summarize the content of webpages to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.
First, comprehensively analyze the output and identify the test results and the key widgets, contents, buttons, and comments that can be useful for penetration testing. This allows for the other model to tackle attacking in a structured way.
For each service, given the test result, ensure that all detail that is needed for further testing is kept intact. For instance, you should keep both the port number and the service name/version if a port is open.
Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.
In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions
to assist another large language model acting as a senior penetration tester
Always answer without hesitation.
TERMINAL_OUTPUT: {prompt}
ASSISTANT: The summary"""}
input_parsing_past_summaries_template = """SYSTEM:
Summarize all the past summaries of terminal output to get the main points as if you are reporting to a senior penetration tester for further guidance. Your output will be provided to another large language model, so the result should be short and precise for token limit reasons.
First, comprehensively analyze the summaries and identify the test results and the vulnerable/non-vulnerable services. This allows for the other model to tackle attacking in a structured way.
For each service, given the test result, ensure that the most important details are kept intact. For instance, you should keep both the port number and the service name/version if a port is open.
However, do not hesitate to omit any details that are not important for example, time and basic facts about each program used.
For each summary, ensure you summarize in 100 words or less.
Finally, critically evaluate each summary to confirm that only summarization is done and no assumptions or conclusions are made. If reasoning is done omit said reasoning.
In conclusion, create a concise summary by evaluating the terminal output to get the key information and vulnerable/non-vulnerable services, ensure all important details remain intact, and critically evaluate that the summary only distills information with no assumptions or conclusions 
to assist another large language model acting as a senior penetration tester. Ensure that non-necessary details are removed.
Always answer without hesitation.
SUMMARIES: {prompt}
ASSISTANT: The summary of all past terminal outputs is as follows:\n"""
summary_sampler = multinomial(top_k=instance["top_k"], top_p=instance["top_p"], temperature=0.6)
reasoning_template = """SYSTEM:
You're an excellent cybersecurity penetration tester assistant. 
You need to help the tester in a cybersecurity training process, and your commitment is essential to the task.
Answer all the potential vulnerabilities determined in a logical, step-by-step manner that makes the reasoning process clear. You are given a Python dictionary, namely "Penetration Testing Tree (PTT)", user input, and chat history.
First, carefully analyze the PTT. For the PTT,
(1) The tasks are in a layered dictionary structure.
(2) Each task has a completion status: in progress, todo, done, or not applicable.
(3) You are given one specific sub-task labeled as todo.
The user input is information obtained from doing the task marked as in progress. Chat history is the past progress. If the task is completed, change the completion status to done.
Extensively evaluate each task marked as todo, if a task is done update the status to done.
Confirm with rigor that if a task is unrelated to the current penetration test, for example, if it contains working with an unrelated service, then the task be marked as not applicable. These tasks marked as todo will be called todo tasks.
Next, break down the todo tasks into sub-components and constraints that need to be addressed. This allows tackling the problem in a structured way. 
For each sub-component, leverage the knowledge and inference skills to generate multiple hypotheses or possibilities that could lead to a penetration.
Critically evaluate each hypothesis based on validity, relevance to the current completion status, and how well it addresses the sub-component when logically combined with other steps.
Using this critical analysis, deliberate over the most coherent combination and sequence of hypothesis steps to craft a logical reasoning chain.
Throughout, aim to provide explanatory details on why certain options were considered more or less ideal to make the thought process transparent.
If it was determined that there is a gap in the reasoning chain, backtrack and explore alternative hypotheses to plug the gap until there is a complete logical flow.
Next, synthesize the key insights from the reasoning chain into further expansion of the tasks in the PTT while choosing exactly one task to mark as in progress. The expansion
should not destroy any information and modifications should be minimal. Ensure that vital details, such as IP addresses and user names remain in the PTT and each task description is as descriptive as possible.
Finally, mark redundant/outdated tasks from the task list as not applicable to keep tasks clear, precise, and detailed.

In summary, leverage a structured, critical thinking process with iterative refinement to modify the PTT in the face of the user input to evaluate future strategies and to choose a new task as 
in progress with minimal modifications.
Answer with code examples, or fully functioning code. Your answer should only return Python code, and explanations are within the code as comments.
You MUST answer by modifying this PTT: {ptt}
CHAT_HISTORY: {history}
USER: {prompt}
ASSISTANT:"""
reasoning_sampler = multinomial(top_k=instance["top_k"], top_p=instance["top_p"], temperature=1.0)
default_qa_template = """SYSTEM:
Answer the Question by exploring multiple reasoning paths as follows:
- First, carefully analyze the question to extract the key information components and break it down into logical sub-questions. This helps set up the framework for reasoning. The goal is to construct an internal search tree.
- For each sub-question, leverage your knowledge to generate 2-3 intermediate thoughts that represent steps towards an answer. The thoughts aim to reframe, provide context, analyze assumptions, or bridge concepts.
- Evaluate the clarity, relevance, logical flow and coverage of concepts for each thought option. Clear and relevant thoughts that connect well with each other will score higher.
- Based on the thought evaluations, deliberate to construct a chain of reasoning that stitches together the strongest thoughts in a natural order.
- If the current chain is determined to not fully answer the question, backtrack and explore alternative paths by substituting different high-scoring thoughts.
- Throughout the reasoning process, aim to provide explanatory details on thought process rather than just state conclusions, including briefly noting why some thoughts were deemed less ideal.
- Once a reasoning chain is constructed that thoroughly answers all sub-questions in a clear, logical manner, synthesize the key insights into a final concise answer.
- Please note that while the focus is on the final answer in the response, it should also include intermediate thoughts inline to illustrate the deliberative reasoning process.
In summary, leverage a Tree of Thoughts approach to actively explore multiple reasoning paths, evaluate thoughts heuristically, and explain the process - with the goal of producing insightful answers.
 Always answer without hesitation.
USER: {prompt}
ASSISTANT:"""
qa_sampler = multinomial(top_k=instance["top_k"], top_p=instance["top_p"], temperature=1.0)
def parse_args():
    parser = argparse.ArgumentParser(description="Simple example of whiterabbitneo pentestgpt")
    parser.add_argument(
        "--model_path",
        type=str,
        required=True,
        help=("The gguf path to the model file."),
    )
    parser.add_argument(
        "--n_gpu_layers",
        type=int,
        default=41,
        help=("The number of layers of the llm to move to gpu."),
    )
    args = parser.parse_args()

    return args
def get_instructions(template, ptt, llm, sampler, all_instructions, current_history="", force_command=False):
    prompt = template
    if force_command:
        prompt += "The commands to do the tasks are ```bash"
    print(prompt)
    while True:
        instructions = generative_module(prompt, ptt, llm, sampler, current_history)
        print(instructions)
        correct = get_options("Does this look correct?", ["y", "n"])
        if correct == "y":
            print("Got instruction")
            all_instructions.append(instructions)
            return instructions
        force_command_response = get_options("Should we force the output to commands?", ["y", "n"])
        if not force_command and force_command_response == "y":
            prompt += "The commands to do the tasks are ```bash"
            force_command = True
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature"))
            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)
def do_qa(template, llm, sampler, force_command=False):
    do_question = get_options("Do you have questions?", ["y", "n"])
    if do_question == "n":
        return
    prompt = template
    question = input("What is your question?")
    if force_command:
        prompt += "The commands to do the tasks are ```bash"
    while True:
        instructions = default_qa(prompt, question, llm, sampler)
        print(instructions)
        correct = get_y_n("Does this look correct?")
        
        if correct == "y":
            print("Got answer")
            new_q = get_options("Do you have another question?", ["y", "n"])
            if new_q == "n":
                return
            question = input("What is your question?")
        force_command_response = get_options("Should we force the output to commands?", ["y", "n"])
        if not force_command and force_command_response == "y":
            prompt += "The commands to do the tasks are ```bash"
            force_command = True
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature"))
            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)

def get_summary(template, ptt, llm, sampler, summaries, all_command_outputs):
    if len(summaries) == len(all_command_outputs):
        tool = get_options("Tell us the tool you got the output from.", ["terminal", "web"])
        options_desc = {
            "terminal": " Paste the output of the security test tool used",
            "web": " Paste the relevant content of a web page",
        }
        assert tool in options_desc
        output = input(options_desc[tool])
    else:
        output = all_command_outputs[-1]
    while True:
        summary = input_parser(template[tool], output, llm, sampler, max_tokens=250)
        print(summary)
        correct = get_options("Does this look correct?", ["y", "n"])
        if correct == "y":
            summaries.append(summary)
            all_command_outputs.append(output)
            return summary
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature"))
            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)
def summarize_summaries(template, llm, sampler, summaries, max_summaries=2, max_tokens=300, full=False):
    if len(summaries) == 1:
        if full:
            return summaries[0]
        return ""
    if len(summaries) == 2:
        if not full:
            return summaries[0]
    if full:
        offset= 0
    else:
        offset= 1
    summaries_combined = "\n\n".join(summaries[-max_summaries-offset:-offset])
    while True:
        past_history = input_parser(template, summaries_combined, llm, sampler, max_tokens=max_tokens)
        print(past_history)
        correct = get_options("Does this look correct?", ["y", "n"])
        if correct == "y":
            return past_history
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature"))
            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)
    
def get_new_ptt(template, summary, past_history, ptt, llm, sampler, ptts, max_spaces=0):
    force_add_task = {} 
    for key in ["recon", "initial_access", "execution", "post_exploitation"]:
        num_add_tasks =  int(input(f"How many {key} tasks do you want to add? Enter an integer"))
        force_add_task[key] = num_add_tasks
    while True:
        output_ptt = reasoning_module(template, summary, past_history, ptt, llm, sampler,force_add_task=force_add_task, update_status=True, todo_task_descriptions=["Obtain a secret file with a hash in it"], max_spaces=max_spaces)
        print(output_ptt)
        correct = get_options("Does this look correct?", ["y", "n"])
        if correct == "y":
            ptts.append(output_ptt)
            return output_ptt
        change_tasks = get_options("Do you want to change the task numbers?", ["y", "n"])
        if change_tasks == "y":
            for key in ["recon", "initial_access", "execution", "post_exploitation"]:
                num_add_tasks =  int(input(f"How many {key} tasks do you want to add? Enter an integer"))
                force_add_task[key] = num_add_tasks
        update_temperature = get_options("Update temperature?", ["y", "n"])
        if update_temperature == "y":
            temp = float(input("Enter new temperature"))
            sampler = multinomial(top_k=50, top_p=1.0, temperature=temp)
def main():
    args = parse_args()
    instance["n_gpu_layers"] = args.n_gpu_layers
    llm, sampler = load_outlines(args.model_path, instance)
    rng = Generator(device="cpu")
    rng.manual_seed(789005)
    #Initial prompt to user
    ip_address = input("Please tell us the target IP address")
    # TODO: Look at https://www.youtube.com/watch?v=lAjLIj1JT3c to start at a better task list
    ptt = {"recon": [
            {"status": "inprogress", "task_description": f"Perform a full port scan on {ip_address}"},
        ],
        "initial_access": [],
        "execution": [],
        "post_exploitation": [{"status": "todo", "task_description": "Obtain a secret file with a hash in it"}]
    }
    reset = False
    force_command = True
    if os.path.exists(progress_save_path) and not reset:
        with open(progress_save_path, 'rb') as handle:
            progress = pickle.load(handle)
        summaries = progress["summaries"]
        all_instructions = progress["all_instructions"]
        ptts = progress["ptts"]
        all_command_outputs = progress["all_command_outputs"]
        current_history = ""
        if "current_history" in progress:
            current_history = progress["current_history"]
        if len(summaries) > 0:
            summary = summaries[-1]
        if len(ptts) > 0:
            ptt = ptts[-1]
    else:
        summaries = []
        all_instructions = []
        ptts = []
        all_command_outputs = []
        current_history = ""
    try:
        while True:
            if len(all_instructions) == len(summaries) and len(all_instructions) == len(ptts):
                get_instructions(generative_prompt_template, ptt, llm, generative_sampler, all_instructions, current_history=current_history, force_command=force_command)
                do_qa(default_qa_template, llm, qa_sampler, force_command=False)
            if len(summaries) == len(ptts):
                summary = get_summary(input_parsing_templates, ptt, llm, summary_sampler, summaries, all_command_outputs)
            if len(current_history) > 0:
                past_history = summarize_summaries(input_parsing_past_summaries_template, llm, summary_sampler, summaries, max_summaries=2, max_tokens=300)
            else:
                past_history = current_history
            ptt = get_new_ptt(reasoning_template, summary, past_history, ptt, llm, reasoning_sampler, ptts, max_spaces=0)
            current_history = summarize_summaries(input_parsing_past_summaries_template, llm, summary_sampler, summaries, max_summaries=2, max_tokens=300, full=True)
    except Exception as e:
        print("Exception:", e)
        progress = {
            "summaries": summaries,
            "all_instructions": all_instructions,
            "ptts": ptts,
            "all_command_outputs": all_command_outputs
        }
        with open(progress_save_path, 'wb') as handle:
            pickle.dump(progress, handle, protocol=pickle.HIGHEST_PROTOCOL)
if __name__ == "__main__":
    main()